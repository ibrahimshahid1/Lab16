{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Y8YZP6McqGVd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iaXDd2j9axp"
      },
      "source": [
        "# **Lab 16: Q-Learning**\n",
        "---\n",
        "\n",
        "**Disclaimer**\n",
        "\n",
        "This notebook is a demonstration of using RL Algorithms - There is a lot of new code so the purpose of the lab is to build exposure and intuition about Reinforcement Learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overview of Lab**\n",
        "---"
      ],
      "metadata": {
        "id": "yfhYEpXxnSS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, you will be using the Q Learning Algorithm, which is a reinforcement learning algorithm. Unlike supervised or unsupervised algorithms, an RL model does not get trained on existing data. Instead, the RL models are fit by exploring an environment which gives them a reward for each decision they make.\n",
        "\n",
        "In today's lab we will learn about an environment called **GridWorld**.\n",
        "\n",
        "Gridworld is a game in which a player aims to travel from the start position to the goal position in the fewest moves possible. We will explore the game ourselves first, understand how rewards are given, and build a reinforcement learning agent that learns to play the game.\n",
        "\n"
      ],
      "metadata": {
        "id": "yVY2O3jXnYKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Learning about the Gridworld**\n",
        "---\n",
        "***Read before implementing***\n",
        "\n",
        "This game is called **Gridworld**. The goal of Gridworld is to get the red block (the player) to the blue block (the goal state) in the shortest distance possible.\n",
        "\n",
        "* `Red` block represents the Agent\n",
        "\n",
        "* `Blue` block represents the Goal State\n",
        "\n",
        "* `Grey` blocks represent obstructions\n",
        "\n",
        "\n",
        "#### **Let's Initialize a game:**\n",
        "\n",
        "Running `new_game = Create_game()` will create a new instance of the game and store it in the variable `new_game`.\n",
        "\n",
        "**Each instance of a game has four useful functions:**\n",
        "\n",
        "1. `new_game.running` will return `True` if the game is in progress or `False` if the game is over.\n",
        "2. `new_game.move(action)` will move the player in the game and returns two values:\n",
        "  `current_state` and `reward`.\n",
        "\n",
        "  ***There are 4 valid moves:***\n",
        "\n",
        "  `0` Will move the player **North**\n",
        "\n",
        "  `1` Will move the player **East**\n",
        "\n",
        "  `2` Will move the player **South**\n",
        "\n",
        "  `3` Will move the player **West** \n",
        "  \n",
        "  As `.move()` returns two values, it is easiest to be called as follows:\n",
        "  ```python\n",
        "  state, reward = new_game.move(action)\n",
        "  ``` \n",
        "\n",
        "3. `new_game.start_pos` will give the starting position of the player.\n",
        "\n",
        "4. `new_game.display()` draws a visual representation of the game.\n",
        "\n",
        "  **There are 2 optional arguments you can pass into `.display`:**\n",
        "    1. `new_game.display(show_reward=True)` shows the reward associated with landing at each positon on the grid.\n",
        "    2. `new_game.display(Q=Qvalues)` - By passing in the Q values of your RL agent you can visualize what the strategy of the Agent at each point of the map."
      ],
      "metadata": {
        "id": "hmMYCISIt1lz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f6t0yYBhCsm"
      },
      "source": [
        "## **Part 1: Practice Together**\n",
        "---\n",
        "*Follow along with your TA to implement your first RL algorithm*\n",
        "\n",
        "In Part 1 we will do the following:\n",
        "\n",
        "1. Load in the game\n",
        "2. Familiarize ourselves with the game and the associated rules\n",
        "3. Create and train the RL agent\n",
        "4. Observe the Agent playing the game\n",
        "5. Visualize the strategy of the Agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZZT5pJqia_E"
      },
      "source": [
        "### **Step \\#0: Import the following before continuing**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import time"
      ],
      "metadata": {
        "id": "wIFjOovZtwtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5iUBJ9h6b3x"
      },
      "source": [
        "### **Step \\#1: Load the Game generator**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This game generator, which is mostly for drawing the game visualizations, is completed for you. You may look at the code inside it, *but please do not edit it*.\n",
        "\n",
        "The code is hidden but ***you must run the following cell.***"
      ],
      "metadata": {
        "id": "IBY4Y8zBF24t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create_game() { display-mode: \"form\" }\n",
        "class Create_game():\n",
        "  def __init__(self):\n",
        "    # Game is running\n",
        "    self.running = True\n",
        "    self.display_init = False\n",
        "    self.display_update = False\n",
        "    # self.display_clear = False\n",
        "    \n",
        "    # Create border for 12x12\n",
        "    self.grid = (12,12)\n",
        "    self.blocks = np.array([142, 143, 3, 35, 8, 135, 84, 120, 139, 36, 133, 4, 9, 131,\n",
        "                   71, 132, 23, 141, 5, 48, 10, 0, 59, 137, 138, 140, 119, 6, \n",
        "                   11, 60, 1, 96, 136, 12, 95, 7, 107, 134, 47, 2, 72, 108, 24, 83])\n",
        "\n",
        "    # Add in goal, agent block\n",
        "    self.goal_pos = 33\n",
        "    self.start_pos = 75\n",
        "    self.player_pos = 75\n",
        "    \n",
        "    # Create Reward Table\n",
        "    self.rewards = np.ones((144)) * -1\n",
        "    self.rewards[self.blocks] = -10\n",
        "    self.rewards[self.goal_pos] = 50\n",
        "   \n",
        "  def display(self, show_rewards=False, Q=None):\n",
        "    if self.display_init:\n",
        "      self.ax.set_title(\"The Land of GridWorld\")\n",
        "      self.ax.axis('off')\n",
        "      if show_rewards:\n",
        "        for pos in range(len(self.rewards)):\n",
        "            i, j = np.unravel_index(pos, self.grid, order=\"F\")\n",
        "            self.ax.text(i,j,self.rewards[pos],ha='center',va='center')\n",
        "            self.display_init = False\n",
        "      elif Q is not None:\n",
        "        for pos in range(len(Q)):\n",
        "          i, j = np.unravel_index(pos, self.grid, order=\"F\")\n",
        "          arrow_dict = {0:(0,0.4),1:(0.4,0),2:(0,-0.4),3:(-0.4,0)}\n",
        "          dx, dy = arrow_dict[np.argmax(Q[pos,:])]\n",
        "          self.ax.arrow(i, j , dx , dy , fc=\"k\", ec=\"k\", head_width=0.1, head_length=0.1)\n",
        "        self.display_init = False\n",
        "      temp_board = self.visual_board.copy()\n",
        "      temp_board[self.player_pos] = (240, 15, 60)\n",
        "      self.ax.imshow(temp_board.reshape(*self.grid,3), origin=\"lower\")\n",
        "      if self.display_update:\n",
        "        self.hdisplay.update(self.fig)\n",
        "      self.display_update = True\n",
        "\n",
        "    else:\n",
        "       # Prepare Rendering Engine\n",
        "      self.hdisplay = display.display(\"12x12 Game Board\", display_id=True)\n",
        "      self.fig, self.ax = plt.subplots(figsize=(7,7))\n",
        "      # Create Visual Board\n",
        "      self.visual_board = np.array([(255,255,255) for _ in range(144)])\n",
        "      self.visual_board[self.goal_pos] = (11, 218, 222)\n",
        "      self.visual_board[self.blocks] = (120, 124, 125)\n",
        "      self.display_init = True\n",
        "      self.display_update = False\n",
        "      self.display(show_rewards=show_rewards, Q=Q)\n",
        "\n",
        "  def move(self, action):\n",
        "    move_dict = {0:(1,0),1:(0,1),2:(-1,0),3:(0,-1)}\n",
        "    # Convert action to a proposed new state in flat form\n",
        "    cartesian_pos = np.unravel_index(self.player_pos, self.grid)\n",
        "    move = move_dict[action]\n",
        "    new_cartesian_pos = np.array(cartesian_pos) + np.array(move)\n",
        "    new_pos = np.ravel_multi_index(new_cartesian_pos, self.grid)\n",
        "\n",
        "    if new_pos == self.goal_pos:\n",
        "      # Reached Goal State\n",
        "      self.running = False\n",
        "      self.player_pos = new_pos\n",
        "    elif new_pos not in self.blocks:\n",
        "      # Valid Move\n",
        "      self.player_pos = new_pos\n",
        "\n",
        "    return (self.player_pos, self.rewards[new_pos])"
      ],
      "metadata": {
        "id": "XnqIJUvXEDIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step #1.5 Play the game ourselves**\n",
        "---\n",
        "***This code is completed for you***\n",
        "\n",
        "The Game can be played as a traditional user input game. Run this cell to open up an input box. \n",
        "\n",
        "To move the player (the red square) around, input:\n",
        "0. North (Up)\n",
        "1. East (Right)\n",
        "2. South (Down)\n",
        "3. West (Left)"
      ],
      "metadata": {
        "id": "0DHJBrRpzmxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the game with Human Input\n",
        "simple_grid = Create_game()\n",
        "while simple_grid.running:\n",
        "  simple_grid.display()\n",
        "  simple_grid.move(int(input(\"Enter your move: \")))"
      ],
      "metadata": {
        "id": "pvZ_c5xdt4uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can show the rewards associated with each position by passing the argument `show_rewards=True` into the display function:\n",
        "\n",
        "***Run the code below to view the rewards for each position on the map.***\n"
      ],
      "metadata": {
        "id": "w_Za4vSviSSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_grid.display(show_rewards=True)"
      ],
      "metadata": {
        "id": "dMHEdX6J3VIc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "66fc0fbe-6d22-4ed5-e5fc-8920f876a0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#2, #3, and #4: Create the RL Agent**\n",
        "---\n",
        "\n",
        "In order to make the agent, you must create a **Q table** that is of the correct size (no. of states, no. actions).\n",
        "\n",
        "Each column in our table represents taking a specific action. Therefore, column 0 represents action 0.\n",
        "\n",
        "If we have a 12 x 12 grid, there are **144 states**.\n",
        "\n",
        "If we can move `N`,`S`,`E`,`W` there are **4 actions**.\n",
        "\n",
        "The general pseudocode is as follows:\n",
        "\n",
        "```pseudocode\n",
        "Create a Q table full of random numbers.\n",
        "\n",
        "for episode in 100:\n",
        "  Create a game\n",
        "  Set the current_state equal to the starting game position\n",
        "  while the game is running:\n",
        "    Take the action which has the highest value for the current state\n",
        "    Make a move in the game using that action and record the new_state and reward\n",
        "    Update the Q table according to the Q function\n",
        "    Update the current state to the new state\n",
        "```\n",
        "\n",
        "### **The Q function:**\n",
        "\n",
        "$$\n",
        "Q[S,A] = Q[S,A] + \\alpha \\{ reward + \\gamma\\max (Q[S_{new}]) - Q[S,A] \\}\n",
        "$$\n",
        "\n",
        "For our purposes we will set the learning rate $\\alpha$ `alpha = 0.5` and the discount factor $\\gamma$ `gamma = 0.8` \n",
        "\n",
        "### **Useful functions:**\n",
        "\n",
        "**Generating a table of random numbers**\n",
        ">The `np.random.rand(x,y)` will create a grid of random numbers with `x` rows and `y` columns.\n",
        "\n",
        "**Getting the position of the max value of an arrar**\n",
        "> The `np.argmax(array)` will return the (zero indexed) position of the max value. For example `np.argmax([2,4,1,9,7,5])` will return `3`."
      ],
      "metadata": {
        "id": "hyQ-ODHIFZ1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.random.rand(144,4)\n",
        "alpha = 0.5\n",
        "gamma = 0.8\n",
        "\n",
        "for episode in range(100):\n",
        "  game = Create_game()\n",
        "  state = game.player_pos\n",
        "  while game.running:\n",
        "\n",
        "    # Choose an Action\n",
        "    action = np.argmax(Q[state])\n",
        "\n",
        "    # Make a move in the Game\n",
        "    new_state, reward = game.move(action)\n",
        "\n",
        "    # Update the Q table\n",
        "    Q[state, action] += 0.5*(reward + 0.8*np.max(Q[new_state]) - Q[state,action])\n",
        "\n",
        "    # Update the State\n",
        "    state = new_state"
      ],
      "metadata": {
        "id": "FguJYFNkpS_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#5: Watch the Agent play the game - did it learn correctly?**\n",
        "---\n",
        "\n",
        "***This code is completed for you.***\n",
        "\n",
        "To use the function, pass in the variable containing your Q values and the variable containing the game generator (here it is called `Create_game`)."
      ],
      "metadata": {
        "id": "NQy_QoPdGEwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your agent!\n",
        "def test_agent(Q, Game):\n",
        "  test_game = Game()\n",
        "  state = test_game.player_pos\n",
        "\n",
        "  while test_game.running:\n",
        "    time.sleep(0.3)\n",
        "    action = np.argmax(Q[state])\n",
        "    state, _ = test_game.move(action)\n",
        "    test_game.display()\n",
        "    \n",
        "  if state == test_game.goal_pos:\n",
        "    print(\"Agent Reached the Goal!\")\n",
        "\n",
        "# Pass your Q value table into this function below\n",
        "test_agent(Q, Create_game)"
      ],
      "metadata": {
        "id": "-hCnbVtUii4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#6: Observe the strategy of the RL Agent.**\n",
        "---\n",
        "\n",
        "The code below will produce an arrow at each square in the gridworld representing which action has the highest value. That is to say, if you agent lands on a given square, the arrow shows where they will move next.\n",
        "\n",
        "**Run the code below to look at where the arrows are pointing. Do you see a path to the goal?**"
      ],
      "metadata": {
        "id": "b-_wk0TwIg7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the Strategy of the Q learning Agent \n",
        "s = Create_game()\n",
        "s.display(Q=Q)"
      ],
      "metadata": {
        "id": "sUH893_z5ywL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ngQ1FcJJLsY"
      },
      "source": [
        "## **Part 2: Gridworld level 2**\n",
        "--- \n",
        "*Now, you will create a RL algorithm on your own*\n",
        "\n",
        "In part 2 we will be building a very similar RL agent as we did in part 1, but this time **Gridworld** has obstacles in the map!\n",
        "\n",
        "Just as we did in Part 1 we will do the following in Part 2:\n",
        "\n",
        "1. Load in the new `game2`\n",
        "2. Familiarize ourselves with the new game and the associated rules\n",
        "3. Create and train the RL agent\n",
        "4. Observe the Agent playing the game\n",
        "5. Visualize the strategy of the Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **If you want a reminder of the rules of the game, check out below:**"
      ],
      "metadata": {
        "id": "Y8YZP6McqGVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Learning about the game**\n",
        "---\n",
        "\n",
        "`Create_game2` is a game generator that is very similar to the `Create_game` generator above before. `Create_game2` creates a variation on **Gridworld** that includes obstacles in the path of the solver.\n",
        "\n",
        "The rules remain the same and are repeated below:\n",
        "\n",
        "The goal of this game is to get the red block (the player) to the blue block (the goal state) in the shortest distance possible.\n",
        "\n",
        "* `Red` block represents the Agent\n",
        "\n",
        "* `Blue` block represents the Goal State\n",
        "\n",
        "* `Grey` blocks represent obstructions\n",
        "\n",
        "\n",
        "#### **Let's Initialize a game**:\n",
        "\n",
        "Running `game2 = Create_game2()` will create a new instance of the game and store it in the variable `game2`.\n",
        "\n",
        "**Each instance of a game has four useful functions:**\n",
        "\n",
        "1. `game2.running` will return `True` if the game is in progress or `False` if the game is over.\n",
        "2. `game2.move(action)` will move the player in the game and returns two values:\n",
        "  `current_state` and `reward`.\n",
        "\n",
        "  ***There are 4 valid moves:***\n",
        "\n",
        "  `0` Will move the player **North**\n",
        "\n",
        "  `1` Will move the player **East**\n",
        "\n",
        "  `2` Will move the player **South**\n",
        "\n",
        "  `3` Will move the player **West** \n",
        "  \n",
        "  As `.move()` returns two values it is easiest to be called as follows:\n",
        "  ```python\n",
        "  state, reward = new_game.move(action)\n",
        "  ``` \n",
        "\n",
        "3. `game2.start_pos` will give the starting position of the player.\n",
        "\n",
        "4. `game2.display()` draws a visual representation of the game.\n",
        "\n",
        "  **There are 2 optional arguments you can pass into `.display`:**\n",
        "    1. `game2.display(show_reward=True)` shows the reward associated with landing at each positon on the grid.\n",
        "    2. `game2.display(Q=Qvalues)` - By passing in the Q values of your RL agent you can visualize what the strategy of the Agent at each point of the map."
      ],
      "metadata": {
        "id": "4a2xLCXsJqHY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL0HC8ITJLsZ"
      },
      "source": [
        "### **Step \\#0: Import the following before continuing**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython import display\n",
        "import time"
      ],
      "metadata": {
        "id": "WjbVGFPeJZWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIrdeSbYJhiX"
      },
      "source": [
        "### **Step \\#1: Load the Game generator**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This game generator is completed for you! You may look at the code inside it, *but please do not edit it*. Most of this code is for drawing the game visualizations!\n",
        "\n",
        "The code is hidden but ***you must run the following cell***"
      ],
      "metadata": {
        "id": "x7vWzWRZJhiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create_game2 {display-mode: \"form\"}\n",
        "class Create_game2(Create_game):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    obstacles = [121, 22, 122, 14, 92, 3, 68, 88, 7, 89, 114, 45, 88, 74, 119]\n",
        "    self.blocks = np.r_[self.blocks, obstacles]\n",
        "    self.agent_pos = 87\n",
        "    self.rewards = np.ones((144)) * -1\n",
        "    self.rewards[self.blocks] = -10\n",
        "    self.rewards[self.goal_pos] = 50"
      ],
      "metadata": {
        "id": "FNT-XXGeuaeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Let's take a look at the new map**:\n",
        "---\n",
        "\n",
        "Hopefully you should be able to see some obstacles blocking the path to the Goal!\n",
        "\n",
        "These obstacles are represented by grey blocks and the agent receives a penalty for trying to move into them."
      ],
      "metadata": {
        "id": "HkrTOGsmKUv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "game2 = Create_game2()\n",
        "game2.display()"
      ],
      "metadata": {
        "id": "rGB8Otp40OAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#2, #3, and #4: Create the RL Agent**\n",
        "---\n",
        "\n",
        "You have already seen this in Part 1:\n",
        "\n",
        "It is now time to create a Q table, and begin tuning it to make our RL agent learn!\n",
        "\n",
        ">**Knowledge check!**<br>\n",
        "If we have a 12x12 grid, how many states would we have? <br>\n",
        "If there are 4 possible moves, how many actions are there? <br>\n",
        "Using these two, how big must our Q table be?\n",
        "\n",
        "As a reminder, a Q table acts as the memory for the Q-learning agent. It stores a value associated with how rewarding a given action is at a given state.\n",
        "\n",
        "*Useful equations and functions that were introduced earlier are repeated below for convenience:*\n",
        "\n",
        "### **The Q function:**\n",
        "\n",
        "$$\n",
        "Q[S,A] = Q[S,A] + \\alpha \\{ reward + \\gamma\\max (Q[S]) - Q[S,A] \\}\n",
        "$$\n",
        "\n",
        "For our purposes we will set the learning rate $\\alpha$ `alpha=0.5` and the discount factor $\\gamma$ `gamma=0.8` \n",
        "\n",
        "### Useful functions:\n",
        "\n",
        "**Generating a table of random numbers**\n",
        ">The `np.random.rand(x,y)` will create a grid of random numbers with `x` rows and `y` columns.\n",
        "\n",
        "**Getting the position of the max value of an arrar**\n",
        "> The `np.argmax(array)` will return the (zero indexed) position of the max value. For example `np.argmax([2,4,1,9,7,5])` will return `3`. \n",
        "\n",
        "**Complete this section**"
      ],
      "metadata": {
        "id": "htCO8yUkKc8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q2 = np.random.rand(144,4)\n",
        "alpha =  # COMPLETE THIS LINE\n",
        "gamma =  # COMPLETE THIS LINE\n",
        "\n",
        "for episode in range(# COMPLETE THIS LINE\n",
        "  game2 = Create_game2()\n",
        "  state = game2.agent_pos\n",
        "  while game2.running:\n",
        "\n",
        "    # Exploitation Step\n",
        "    action = # COMPLETE THIS LINE\n",
        "\n",
        "    # Make a move in the Game2\n",
        "    new_state, reward = # COMPLETE THIS LINE\n",
        "\n",
        "    # Update the Q2 table\n",
        "    Q2[state, action] += # COMPLETE THIS LINE\n",
        "\n",
        "    # Update the State\n",
        "    state = # COMPLETE THIS LINE"
      ],
      "metadata": {
        "id": "77JSfgxnsfbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#5: Watch the Agent play the game - did it learn correctly?**\n",
        "---\n",
        "\n",
        "***This code is completed for you.*** \n",
        "\n",
        "We will use the same function as before, but we will pass in the variable containing our new Q values and the variable containing the game2 generator (here it is called `Create_game2`)."
      ],
      "metadata": {
        "id": "n_wM6v8rKhtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your agent!\n",
        "def test_agent(Q, Game):\n",
        "  test_game = Game()\n",
        "  state = test_game.player_pos\n",
        "\n",
        "  while test_game.running:\n",
        "    time.sleep(0.3)\n",
        "    action = np.argmax(Q[state])\n",
        "    state, _ = test_game.move(action)\n",
        "    test_game.display()\n",
        "    \n",
        "  if state == test_game.goal_pos:\n",
        "    print(\"Agent Reached the Goal!\")\n",
        "\n",
        "# Pass your Q value table into this function below\n",
        "test_agent(Q2, Create_game2)"
      ],
      "metadata": {
        "id": "WK4S-IVn14Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step \\#6: Observe the strategy of the RL Agent.**\n",
        "---\n",
        "\n",
        "***Run the code below to visualize the strategy of your agent.***"
      ],
      "metadata": {
        "id": "jIqeZUsLK8xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the Strategy of the Q learning Agent \n",
        "s = Create_game()\n",
        "s.display(Q=Q2)"
      ],
      "metadata": {
        "id": "h7Q6TfZZK8xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Congratulations! You've just completed your first Reinforcement Learning project.**\n",
        "\n",
        "\n",
        "Some ways to explore this code further:\n",
        "* Change the number of episodes that the RL agents are allowed to train.\n",
        "* Change the parameters `alpha` and `gamma`.\n",
        "* Attempt creating a new level by altering the hidden code for creating the game. Specifically, there is a list called `obstacles` that lists the position of each obstacle. Simply change the numbers in here to create or remove obstacles."
      ],
      "metadata": {
        "id": "QyR3b54jrTYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "© 2023 The Coding School, All rights reserved"
      ],
      "metadata": {
        "id": "9zW6NkGQrOrK"
      }
    }
  ]
}